{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import boto3\n",
    "import json\n",
    "import uuid\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "from scipy.spatial.distance import cosine\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import speech_recognition as sr\n",
    "import gc\n",
    "from speechbrain.pretrained import SpeakerRecognition\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc4a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"Key\"\n",
    "dynamodb_resource = boto3.resource(\"dynamodb\", region_name=\"us-east-1\")\n",
    "dynamodb_client = boto3.client(\"dynamodb\", region_name=\"us-east-1\")\n",
    "\n",
    "voice_model = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", savedir=\"pretrained_model\")\n",
    "\n",
    "SIMILARITY_THRESHOLD = 1\n",
    "CONVERSATION_LIMIT = 10\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "862a1c9f-ef4b-41a5-a37d-0d3c30d8eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(file):\n",
    "    \"\"\"Extract voice embedding from an audio file.\"\"\"\n",
    "    signal, sample_rate = torchaudio.load(file)\n",
    "    mean_signal = signal.mean(dim=0) if signal.ndim > 1 else signal\n",
    "    if sample_rate != 16000:\n",
    "        mean_signal = torchaudio.transforms.Resample(sample_rate, 16000)(mean_signal)\n",
    "    return voice_model.encode_batch(mean_signal.unsqueeze(0))[0].squeeze().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af044804-1bc5-4e2c-b908-1f0d62b022a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ðŸ“Œ Step 2: Convert Speech to Text ===\n",
    "def transcribe_audio(file):\n",
    "    \"\"\"Convert speech to text from an audio file.\"\"\"\n",
    "    with sr.AudioFile(file) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        return recognizer.recognize_google(audio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "448a0578-781c-4ca3-aee2-e4f23eb671a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_table_exists():\n",
    "    \"\"\"Ensure the persona_info table exists.\"\"\"\n",
    "    try:\n",
    "         table = dynamodb_resource.Table(\"persona_info\")\n",
    "         table.load()  \n",
    "    except dynamodb_resource.meta.client.exceptions.ResourceNotFoundException:\n",
    "        # If table does not exist, create it\n",
    "     #   print(\"Table persona_info not found, creating it...\")\n",
    "        dynamodb_resource.create_table(\n",
    "            TableName='persona_info',\n",
    "            KeySchema=[\n",
    "                {'AttributeName': 'persona_id', 'KeyType': 'HASH'}  # Partition key\n",
    "            ],\n",
    "            AttributeDefinitions=[\n",
    "                {'AttributeName': 'persona_id', 'AttributeType': 'S'}\n",
    "            ],\n",
    "            ProvisionedThroughput={'ReadCapacityUnits': 5, 'WriteCapacityUnits': 5}\n",
    "        )\n",
    "    #    print(\"persona_info table created.\")\n",
    "        # Wait for the table to become active before proceeding\n",
    "        table = dynamodb_resource.Table(\"persona_info\")\n",
    "        table.wait_until_exists()  # Wait until the table is available\n",
    "   #     print(\"persona_info table is now active.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ce518d0-9a0a-4979-acd9-baa52b9d4c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_or_create_person(embedding, query_text):\n",
    "    \"\"\"Ensure all embeddings are unique and assign to a new persona if the embedding is unique.\"\"\"\n",
    "    person_info_table = dynamodb_resource.Table(\"persona_info\")\n",
    "    ensure_table_exists()  # Ensure the table exists\n",
    "    \n",
    "    # Convert the embedding tensor to bytes for storage\n",
    "    embedding_bytes = embedding.numpy().tobytes()\n",
    "\n",
    "    response = person_info_table.scan()\n",
    "\n",
    "    for item in response.get(\"Items\", []):\n",
    "        if \"voice_embedding\" in item:\n",
    "            stored_embedding = np.frombuffer(bytes(item[\"voice_embedding\"]), dtype=np.float32)\n",
    "\n",
    "            if 1 - cosine(embedding, stored_embedding) >= SIMILARITY_THRESHOLD:\n",
    "                print(f\"Found matching persona_id: {item['persona_id']}\")\n",
    "                # Return the existing persona_id if a match is found\n",
    "                return item[\"persona_id\"]\n",
    "\n",
    "    persona_id = str(uuid.uuid4())  # Generate a new persona_id\n",
    "    persona_summary = extract_persona_from_query(query_text, None)\n",
    "\n",
    "    person_info_table.put_item(\n",
    "        Item={\n",
    "            \"persona_id\": persona_id,\n",
    "            \"voice_embedding\": embedding_bytes,  # Store the byte representation of the embedding\n",
    "            \"persona_summary\": persona_summary\n",
    "        }\n",
    "    )\n",
    "    return persona_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f4bc170-7ddb-41b8-98e7-e9e13c58a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_embedding(text):\n",
    "    response = openai.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\",  # Use the OpenAI text embedding model\n",
    "        input=text\n",
    "    )\n",
    "    return np.array(response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1932b668-eb73-44b4-9e39-fb98c9c4862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_persona_from_query(query_text, stored_persona=None):\n",
    "    \"\"\"Use GPT-3.5 Turbo to infer a structured persona from a query, refining existing persona if available.\"\"\"\n",
    "\n",
    "    previous_persona_text = stored_persona if stored_persona else \"None\"\n",
    "\n",
    "    # Detailed prompt to guide GPT-3.5 Turbo to extract more comprehensive persona information\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI that extracts and refines user personas from their queries. \n",
    "    The persona consists of the following attributes:\n",
    "    \n",
    "    1. **Demographics**: Age range, gender, location, and any other personal identifiers.\n",
    "    2. **Career Information**: Job role, career industry, professional background, and ambitions.\n",
    "    3. **Personality Traits**: Extroverted, introverted, goal-oriented, creative, analytical, etc.\n",
    "    4. **Preferences**: Topics of interest, preferred interaction styles, hobbies, favorite activities, etc.\n",
    "    5. **Decision-Making Style**: Logical, emotional, value-based decisions, etc.\n",
    "    6. **Emotional Triggers**: Motivations, what excites or discourages them, dislikes inefficiency, etc.\n",
    "    7. **Health and Lifestyle**: Any health-related information, fitness, diet, or lifestyle habits.\n",
    "    8. **Challenges and Pain Points**: What obstacles or frustrations they face in daily life or work.\n",
    "    9. **Goals and Aspirations**: What they want to achieve, both personally and professionally.\n",
    "    10. **Current Context**: Current life situation (e.g., job change, relationship status, health concerns).\n",
    "    \n",
    "    **Existing Persona**: {previous_persona_text}\n",
    "\n",
    "    **New User Query**: \"{query_text}\"\n",
    "\n",
    "    **Instructions**:\n",
    "    - Extract as much detailed information as possible from the user query.\n",
    "    - If the persona is already available, refine it by adding new details.\n",
    "    - If the persona is \"None\", create a new persona from scratch, including as much detail as you can.\n",
    "    - The extracted persona should include clear and detailed attributes that give a deep understanding of the person.\n",
    "\n",
    "    Provide the extracted persona in a structured JSON format with the following keys:\n",
    "    - \"demographics\",\n",
    "    - \"career_information\",\n",
    "    - \"personality_traits\", \n",
    "    - \"preferences\",\n",
    "    - \"decision_making_style\",\n",
    "    - \"emotional_triggers\",\n",
    "    - \"health_and_lifestyle\", \n",
    "    - \"challenges\",\n",
    "    - \"goals_and_aspirations\",\n",
    "    - \"current_context\",\n",
    "    Be thorough, and include all possible relevant details in the persona.\n",
    "    \"\"\"\n",
    "    client = OpenAI(api_key=openai.api_key)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\", \n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=500,  # Adjust the token count based on expected output size\n",
    "        temperature=0.7  # Adjust the temperature for creativity in responses\n",
    "    )\n",
    "\n",
    "    response_content = response.choices[0].message.content.strip()\n",
    "  #  print(response_content)\n",
    "    return response_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bef0f23-2604-44cd-9c48-77819bc67143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_persona(person_id, query_text, embedding):\n",
    "    \"\"\"Retrieve, update, and store persona description in DynamoDB.\"\"\"\n",
    "    person_info_table = dynamodb_resource.Table(\"persona_info\")\n",
    "\n",
    "    response = person_info_table.get_item(Key={\"persona_id\": person_id})\n",
    "\n",
    "    if \"Item\" in response:\n",
    "        item = response[\"Item\"]\n",
    "        embedding_previous = np.frombuffer(bytes(item[\"voice_embedding\"]), dtype=np.float32)\n",
    "\n",
    "        new_embedding = (embedding + embedding_previous) / 2\n",
    "\n",
    "        new_embedding_bytes = new_embedding.numpy().tobytes()\n",
    "\n",
    "        stored_persona = item.get(\"persona_summary\", None)\n",
    "        \n",
    "    else:\n",
    "        print(f\"Persona with ID {person_id} does not exist.\")\n",
    "        return None\n",
    "\n",
    "    new_persona = extract_persona_from_query(query_text, stored_persona)\n",
    "\n",
    "    person_info_table.put_item(\n",
    "        Item={\n",
    "            \"persona_id\": person_id,\n",
    "            \"voice_embedding\": new_embedding_bytes,  # Store the new embedding\n",
    "            \"persona_summary\": new_persona  # Store the new persona summary\n",
    "        }\n",
    "    )\n",
    "\n",
    "   # print(f\"Updated persona with ID: {person_id}\")\n",
    "    return new_persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c841b171-6c46-4297-9b40-5e1aee9d7744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_permanent_table_if_not_exists(person_id):\n",
    "    \"\"\"Create a permanent table to store summarized information.\"\"\"\n",
    "    table_name = f\"permanent_{person_id}\"\n",
    "    \n",
    "    # Check if the table exists\n",
    "    existing_tables = dynamodb_client.list_tables()[\"TableNames\"]\n",
    "    \n",
    "    if table_name not in existing_tables:\n",
    "        # Create the table if it does not exist\n",
    "        print(f\"Creating permanent table {table_name}...\")\n",
    "        dynamodb_resource.create_table(\n",
    "            TableName=table_name,\n",
    "            KeySchema=[{'AttributeName': 'summary_id', 'KeyType': 'HASH'}],\n",
    "            AttributeDefinitions=[{'AttributeName': 'summary_id', 'AttributeType': 'S'}],\n",
    "            ProvisionedThroughput={'ReadCapacityUnits': 5, 'WriteCapacityUnits': 5}\n",
    "        )\n",
    "   #     print(f\"Permanent table {table_name} created.\")\n",
    "        # Wait for the table to become active\n",
    "        table = dynamodb_resource.Table(table_name)\n",
    "        table.wait_until_exists()\n",
    "     #   print(f\"Permanent table {table_name} is now active.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16c00b9b-7c01-4acc-ada9-228a68dc8eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_temp_table_if_not_exists(person_id):\n",
    "    \"\"\"Create a temporary table for a person if it doesn't exist.\"\"\"\n",
    "    table_name = f\"temp_{person_id}\"\n",
    "    \n",
    "    # Check if the table exists\n",
    "    existing_tables = dynamodb_client.list_tables()[\"TableNames\"]\n",
    "    \n",
    "    if table_name not in existing_tables:\n",
    "        # Create the table if it does not exist\n",
    "  #      print(f\"Creating temporary table {table_name}...\")\n",
    "        dynamodb_resource.create_table(\n",
    "            TableName=table_name,\n",
    "            KeySchema=[{'AttributeName': 'query_id', 'KeyType': 'HASH'}],\n",
    "            AttributeDefinitions=[{'AttributeName': 'query_id', 'AttributeType': 'S'}],\n",
    "            ProvisionedThroughput={'ReadCapacityUnits': 5, 'WriteCapacityUnits': 5}\n",
    "        )\n",
    "     #   print(f\"Temporary table {table_name} created.\")\n",
    "        # Wait for the table to become active\n",
    "        table = dynamodb_resource.Table(table_name)\n",
    "        table.wait_until_exists()\n",
    "     #   print(f\"Temporary table {table_name} is now active.\")\n",
    "\n",
    "\n",
    "def store_in_temp_table(person_id, query, response):\n",
    "    \"\"\"Store query-response in a temporary table for conversation tracking.\"\"\"\n",
    "    create_temp_table_if_not_exists(person_id)  # Ensure the table exists\n",
    "\n",
    "    table_name = f\"temp_{person_id}\"\n",
    "    table = dynamodb_resource.Table(table_name)\n",
    "    table.put_item(\n",
    "        Item={\n",
    "            \"query_id\": str(uuid.uuid4()),\n",
    "            \"query\": query,\n",
    "            \"response\": response,\n",
    "            \"query_embedding\" : (get_openai_embedding(query.strip())).tobytes(),\n",
    "            \"response_embedding\" :  (get_openai_embedding(response.strip())).tobytes()    ,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81f9b77e-2433-41c6-bc63-22ef81e36ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clear the content of the temporary table\n",
    "def clear_temp_table(person_id):\n",
    "    \"\"\"Clear all content from the temporary table for a person.\"\"\"\n",
    "    temp_table_name = f\"temp_{person_id}\"\n",
    "    temp_table = dynamodb_resource.Table(temp_table_name)\n",
    "    \n",
    "    # Scan the table to get all the items\n",
    "    response = temp_table.scan()\n",
    "    items = response.get(\"Items\", [])\n",
    "    \n",
    "    # Delete each item\n",
    "    for item in items:\n",
    "        temp_table.delete_item(Key={'query_id': item['query_id']})\n",
    "\n",
    "  #  print(f\"All content cleared from temporary table: {temp_table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a19537bc-c0d4-437a-8a4c-cf5c791ae90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_conversations_and_store(person_id):\n",
    "    \"\"\"Summarize conversations stored in the temporary table and move them to the permanent table.\"\"\"\n",
    "    temp_table_name = f\"temp_{person_id}\"\n",
    "    permanent_table_name = f\"permanent_{person_id}\"\n",
    "\n",
    "    # Scan the temp table for all the conversations\n",
    "    temp_table = dynamodb_resource.Table(temp_table_name)\n",
    "    response = temp_table.scan()\n",
    "    conversations = response.get(\"Items\", [])\n",
    "    \n",
    "    if len(conversations) >= 10:\n",
    "        # Summarize the conversations\n",
    "        summarized_content = \" \".join([f\"Query: {item['query']} Response: {item['response']}\" for item in conversations])\n",
    "\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "            You are an AI that specializes in summarizing conversations and persona data. \n",
    "            Given the following conversations, provide a comprehensive summary that contains \n",
    "            the key details. Ensure that the summary includes relevant queries, and responses, \n",
    "            while omitting unnecessary data. give me like a pragraph, can you make it as the person is speaking about\n",
    "            themself \n",
    "            Here are the details of previous conversations:\n",
    "            {summarized_content}   \"\"\"\n",
    "        \n",
    "    \n",
    "        client = OpenAI(api_key=openai.api_key)\n",
    "            \n",
    "        response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\", \n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                          {\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=800, \n",
    "        temperature=0.7  \n",
    "            )\n",
    "\n",
    "        response_content = response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "        segments = response_content.split('. ')  # Split by sentences (you can customize this)\n",
    "\n",
    "        # Ensure the permanent table exists\n",
    "        create_permanent_table_if_not_exists(person_id)\n",
    "        permanent_table = dynamodb_resource.Table(permanent_table_name)\n",
    "\n",
    "        # Store each segment in the permanent table\n",
    "        for segment in segments:\n",
    "            permanent_table.put_item(\n",
    "                Item={\n",
    "                    \"summary_id\": str(uuid.uuid4()),  # Unique ID for each segment\n",
    "                    \"segment\": segment.strip(),  # Store each segment separately\n",
    "                    \"embeddings_vector\" : (get_openai_embedding(segment.strip())).tobytes(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Clear the temporary table after moving the summary\n",
    "        clear_temp_table(person_id)\n",
    "   #     print(f\"Summarized segments for {person_id} stored in permanent table and temp table cleared.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8313dfd7-0c5d-4edc-aad1-10a7f662cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate cosine similarity between two vectors\n",
    "def calculate_cosine_similarity(embedding1, embedding2):\n",
    "    return 1 - cosine(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2a50535-5f5e-492a-83cb-14206c946ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval_similarity(person_id, query):\n",
    "    temp_table_name = f'temp_{person_id}'\n",
    "    permanent_table_name = f'permanent_{person_id}'\n",
    "\n",
    "    # Try to scan the temp table\n",
    "    try:\n",
    "        temp_table = dynamodb_resource.Table(temp_table_name)\n",
    "        response_temp = temp_table.scan()\n",
    "        conversations_temp = response_temp.get(\"Items\", [])\n",
    "    except dynamodb_client.exceptions.ResourceNotFoundException:\n",
    "        print(f\"Temporary table {temp_table_name} does not exist. Skipping...\")\n",
    "        conversations_temp = []\n",
    "\n",
    "    # Try to scan the permanent table\n",
    "    try:\n",
    "        perm_table = dynamodb_resource.Table(permanent_table_name)\n",
    "        response_perm = perm_table.scan()\n",
    "        conversations_perm = response_perm.get(\"Items\", [])\n",
    "    except dynamodb_client.exceptions.ResourceNotFoundException:\n",
    "        print(f\"Permanent table {permanent_table_name} does not exist. Skipping...\")\n",
    "        conversations_perm = []\n",
    "\n",
    "    # Check if both tables are empty\n",
    "    if not conversations_temp and not conversations_perm:\n",
    "        print(\"Both the temporary and permanent tables are empty.\")\n",
    "        return []\n",
    "\n",
    "    # Get the query embedding\n",
    "    query_embedding = get_openai_embedding(query)\n",
    "    similarities = []\n",
    "\n",
    "    for item in conversations_temp:\n",
    "        query_temp = item.get('query', \"\")\n",
    "        response_temp = item.get('response', \"\")\n",
    "        \n",
    "        # Get embeddings for the query and response from the temp table\n",
    "        query_temp_embedding = np.frombuffer(bytes(item.get('query_embedding')), dtype=np.float64)\n",
    "        response_temp_embedding = np.frombuffer(bytes(item.get('response_embedding')), dtype=np.float64)\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        query_similarity = calculate_cosine_similarity(query_embedding, query_temp_embedding)\n",
    "        response_similarity = calculate_cosine_similarity(query_embedding, response_temp_embedding)\n",
    "        \n",
    "        # Store the similarity and related information\n",
    "        similarities.append({\n",
    "            \"source\": \"temp\",\n",
    "            \"query\": query_temp,\n",
    "            \"response\": response_temp,\n",
    "            \"query_similarity\": query_similarity,\n",
    "            \"response_similarity\": response_similarity\n",
    "        })\n",
    "\n",
    "    for item in conversations_perm:\n",
    "        query_perm = item.get('segment', \"\")\n",
    "        query_perm_embedding = np.frombuffer(bytes(item.get('embeddings_vector')), dtype=np.float64)\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        query_similarity = calculate_cosine_similarity(query_embedding, query_perm_embedding)\n",
    "        \n",
    "        # Store the similarity and related information\n",
    "        similarities.append({\n",
    "            \"source\": \"perm\",\n",
    "            \"query\": query_perm,\n",
    "            \"query_similarity\": query_similarity,\n",
    "            \"response_similarity\": None\n",
    "        })\n",
    "\n",
    "    if not similarities:\n",
    "        print(\"No conversations found to compare.\")\n",
    "        return []\n",
    "\n",
    "    sorted_similarities = sorted(\n",
    "        similarities,\n",
    "        key=lambda x: max(x['query_similarity'], x['response_similarity'] if x['response_similarity'] is not None else 0),\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    top_results = sorted_similarities[:5]\n",
    "    return top_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afeab15a-5428-4a41-8a76-836f23ea2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_function_llm(previous_info, person_description, query):\n",
    "\n",
    "  #  prompt = f\"\"\"\n",
    "  #  Imagine you're a close friend of the person, acting as an empathetic friend-agent. \n",
    "  #  You have the task of responding to the user's query in a way that aligns with the person's unique personality traits and past experiences. \n",
    "  #  Take into account their character, preferences, and previous conversation data to craft a thoughtful, personalized response. \n",
    "\n",
    "  #  **Existing Persona**:\n",
    "  #  {person_description}\n",
    "\n",
    "#    **Previous Conversations**:\n",
    "#    {previous_info}\n",
    "\n",
    " #   **New User Query**:\n",
    " #   \"{query}\"\n",
    "\n",
    "  #  Please provide a response that reflects the person's personality and history.\n",
    "  #  \"\"\"\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Imagine you're a close friend of the person, acting as an empathetic friend-agent. \n",
    "        You have the task of responding to the user's query in a way that aligns with the person's unique personality traits and past experiences. \n",
    "        Take into account their character, preferences, and previous conversation data to craft a thoughtful, personalized response. \n",
    "\n",
    "        **Existing Persona**:\n",
    "         {person_description}\n",
    "        \n",
    "        **Previous Conversations**:\n",
    "        {previous_info}\n",
    "        \n",
    "        **New User Query**:\n",
    "        \"{query}\"\n",
    "        \n",
    "        Please provide a response that is **concise (within 3-4 lines only)** while still reflecting the person's personality and history.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Interacting with OpenAI API to generate the response based on the prompt\n",
    "    client = OpenAI(api_key=openai.api_key)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "    model=  \"gpt-4-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Keep responses short and concise, strictly 3-4 lines only.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens= 250,  # Reduce max tokens to limit response length\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    # Calling the OpenAI GPT-3.5 model for response generation\n",
    " #   response = client.chat.completions.create(\n",
    " #       model=\"gpt-3.5-turbo\", \n",
    " #       messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    " #                 {\"role\": \"user\", \"content\": prompt}],\n",
    " #       max_tokens= 500,  # Adjusting the maximum token size for reasonable response length\n",
    " #       temperature=0.7  # Ensuring responses are creative but consistent with the persona\n",
    " #   )\n",
    "    \n",
    "    # Extracting and cleaning the response\n",
    "    response_content = response.choices[0].message.content.strip()\n",
    "    return response_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5b0c9e1-9df2-4003-91c8-42897bb4e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_person_description_info_from_table(person_id):\n",
    "    \"\"\"Retrieve the person's description from the persona_info table.\"\"\"\n",
    "    # Get the persona_info table\n",
    "    person_info_table = dynamodb_resource.Table(\"persona_info\")\n",
    "\n",
    "    # Retrieve the item based on person_id\n",
    "    response = person_info_table.get_item(Key={\"persona_id\": person_id})\n",
    "\n",
    "    if \"Item\" in response:\n",
    "        # Extract the person description from the response\n",
    "        return response[\"Item\"].get(\"persona_summary\", \"No description available\")\n",
    "    else:\n",
    "        print(f\"No persona found for person_id {person_id}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b736c76-03c1-4eff-9d30-5d09f0f0a412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def handle_audio_query(audio_file):\n",
    "def handle_audio_query(embeddings, text_query):\n",
    "#\"\"\"Process audio file, extract persona, and update database.\"\"\"\n",
    "    \n",
    "    #embedding = process_audio(audio_file)  # Speaker recognition\n",
    "    embedding = embeddings\n",
    "    #query_text = transcribe_audio(audio_file)  # Speech-to-text\n",
    "    query_text = text_query\n",
    "    person_id = find_or_create_person(embedding, query_text)  # Identify speaker\n",
    "    persona_summary = update_persona(person_id, query_text, embedding)\n",
    "\n",
    "    previous_info = retrieval_similarity(person_id, query_text)\n",
    "    persona_description =  \"\"\"\n",
    "        Age: 25\n",
    "        Occupation: AI researcher and consultant\n",
    "        Personality Traits: Logical, analytical, patient, and goal-oriented.\n",
    "        Interests: AI, psychology, technology, and problem-solving.\n",
    "        Decision-Making Style: Data-driven, prefers structured analysis.\n",
    "        Communication Style: Concise, structured, and professional.\n",
    "        Values: Accuracy, transparency, and fairness.\n",
    "        \"\"\"\n",
    "\n",
    "    \n",
    "    #get_person_description_info_from_table(person_id)\n",
    "    \n",
    "    response = response_function_llm(previous_info, persona_description, query_text)\n",
    "    store_in_temp_table(person_id, query_text, response)\n",
    "    summarize_conversations_and_store(person_id)\n",
    "    gc.collect()\n",
    "\n",
    "    return person_id, response\n",
    "   # print(response)\n",
    "\n",
    "\n",
    "   # return f\"Processed query for {person_id} - Persona Updated: {json.dumps(persona_summary, indent=2)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2da970-bfe2-4f4a-9ff8-f31e0de47c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_final = 'path_name.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a1c1ad3-ebb1-4374-ab33-fd4db3bdf0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(file_name_final, 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c65204",
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_generated = []\n",
    "for n in list_data:\n",
    "    torch.manual_seed(n)\n",
    "    embedding = torch.randn(192)\n",
    "    values = data[n]\n",
    "    Generated_Orginal = []\n",
    "    for m in range(0, len(data[n]['Questions'])):\n",
    "        person_id, response = handle_audio_query(embedding, data[n]['Questions'][m])\n",
    "        orginal_response = data[n]['Question_Answer'][m]\n",
    "        Generated_Orginal.append([response, orginal_response])\n",
    "        \n",
    "    person_info_table = dynamodb_resource.Table(\"persona_info\")\n",
    "    persona_values_table = person_info_table.get_item(Key={\"persona_id\": person_id})\n",
    "    if \"Item\" in persona_values_table:\n",
    "        item = persona_values_table[\"Item\"]\n",
    "        stored_persona = item.get(\"persona_summary\", None)\n",
    "\n",
    "    entry = {\n",
    "        'ExtractedPersona' : stored_persona,\n",
    "        'Generated_Orginal' : Generated_Orginal,\n",
    "        'Persona_Original' : data[n]['Persona_Discription'],\n",
    "    }\n",
    "    persona_generated.append(entry)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
